
		From Wikipedia, the free encyclopedia
		
		
		
		
		Jump to navigation
		Jump to search
		General term for the several definitions of mean value, the sum divided by the count
.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}This article is about the mathematical concept. For other uses, see Mean (disambiguation).
For the state of being mean or cruel, see Meanness.
For broader coverage of this topic, see Average.
This article's lead section may be too short to adequately summarize the key points. Please consider expanding the lead to provide an accessible overview of all important aspects of the article.  (October 2021)
There are several kinds of mean in mathematics, especially in statistics.
For a data set, the arithmetic mean, also known as arithmetic average, is a central value of a finite set of numbers: specifically, the sum of the values divided by the number of values. The arithmetic mean of a set of numbers x1, x2, ..., xn is typically denoted by 
  
    
      
        
          
            
              x
              ¯
            
          
        
      
    
    {\displaystyle {\bar {x}}}
  
[note 1]. If the data set were based on a series of observations obtained by sampling from a statistical population, the arithmetic mean is the sample mean (denoted 
  
    
      
        
          
            
              x
              ¯
            
          
        
      
    
    {\displaystyle {\bar {x}}}
  
) to distinguish it from the mean, or expected value, of the underlying distribution, the population mean (denoted 
  
    
      
        μ
      
    
    {\displaystyle \mu }
  
 or 
  
    
      
        
          μ
          
            x
          
        
      
    
    {\displaystyle \mu _{x}}
  
[note 2]).[1]
Outside probability and statistics, a wide range of other notions of mean are often used in geometry and mathematical analysis; examples are given below.

Contents

1 Types of means

1.1 Pythagorean means

1.1.1 Arithmetic mean (AM)
1.1.2 Geometric mean (GM)
1.1.3 Harmonic mean (HM)
1.1.4 Relationship between AM, GM, and HM


1.2 Statistical location

1.2.1 Mean of a probability distribution


1.3 Generalized means

1.3.1 Power mean
1.3.2 f-mean


1.4 Weighted arithmetic mean
1.5 Truncated mean
1.6 Interquartile mean
1.7 Mean of a function
1.8 Mean of angles and cyclical quantities
1.9 Fréchet mean
1.10 Swanson's rule
1.11 Other means


2 See also
3 Notes
4 References



Types of means[edit]
Pythagorean means[edit]
Main article: Pythagorean means
Arithmetic mean (AM)[edit]
Main article: Arithmetic mean
The arithmetic mean (or simply mean) of a list of numbers, is the sum of all of the numbers divided by the number of numbers. Similarly, the mean of a sample 
  
    
      
        
          x
          
            1
          
        
        ,
        
          x
          
            2
          
        
        ,
        …
        ,
        
          x
          
            n
          
        
      
    
    {\displaystyle x_{1},x_{2},\ldots ,x_{n}}
  
, usually denoted by 
  
    
      
        
          
            
              x
              ¯
            
          
        
      
    
    {\displaystyle {\bar {x}}}
  
, is the sum of the sampled values divided by the number of items in the sample


  
    
      
        
          
            
              x
              ¯
            
          
        
        =
        
          
            1
            n
          
        
        
          (
          
            
              ∑
              
                i
                =
                1
              
              
                n
              
            
            
              
                x
                
                  i
                
              
            
          
          )
        
        =
        
          
            
              
                x
                
                  1
                
              
              +
              
                x
                
                  2
                
              
              +
              ⋯
              +
              
                x
                
                  n
                
              
            
            n
          
        
      
    
    {\displaystyle {\bar {x}}={\frac {1}{n}}\left(\sum _{i=1}^{n}{x_{i}}\right)={\frac {x_{1}+x_{2}+\cdots +x_{n}}{n}}}
  

For example, the arithmetic mean of five values: 4, 36, 45, 50, 75 is:


  
    
      
        
          
            
              4
              +
              36
              +
              45
              +
              50
              +
              75
            
            5
          
        
        =
        
          
            210
            5
          
        
        =
        42.
      
    
    {\displaystyle {\frac {4+36+45+50+75}{5}}={\frac {210}{5}}=42.}
  

Geometric mean (GM)[edit]
Main article: geometric mean
The geometric mean is an average that is useful for sets of positive numbers, that are interpreted according to their product (as is the case with rates of growth) and not their sum (as is the case with the arithmetic mean):


  
    
      
        
          
            
              x
              ¯
            
          
        
        =
        
          
            (
            
              
                ∏
                
                  i
                  =
                  1
                
                
                  n
                
              
              
                
                  x
                  
                    i
                  
                
              
            
            )
          
          
            
              1
              n
            
          
        
        =
        
          
            (
            
              
                x
                
                  1
                
              
              
                x
                
                  2
                
              
              ⋯
              
                x
                
                  n
                
              
            
            )
          
          
            
              1
              n
            
          
        
      
    
    {\displaystyle {\bar {x}}=\left(\prod _{i=1}^{n}{x_{i}}\right)^{\frac {1}{n}}=\left(x_{1}x_{2}\cdots x_{n}\right)^{\frac {1}{n}}}
  
  [2]
For example, the geometric mean of five values: 4, 36, 45, 50, 75 is:


  
    
      
        (
        4
        ×
        36
        ×
        45
        ×
        50
        ×
        75
        
          )
          
            
              1
              5
            
          
        
        =
        
          
            
              24
              
              300
              
              000
            
            
              5
            
          
        
        =
        30.
      
    
    {\displaystyle (4\times 36\times 45\times 50\times 75)^{\frac {1}{5}}={\sqrt[{5}]{24\;300\;000}}=30.}
  

Harmonic mean (HM)[edit]
The harmonic mean is an average which is useful for sets of numbers which are defined in relation to some unit, as in the case of speed (i.e., distance per unit of time):


  
    
      
        
          
            
              x
              ¯
            
          
        
        =
        n
        
          
            (
            
              
                ∑
                
                  i
                  =
                  1
                
                
                  n
                
              
              
                
                  1
                  
                    x
                    
                      i
                    
                  
                
              
            
            )
          
          
            −
            1
          
        
      
    
    {\displaystyle {\bar {x}}=n\left(\sum _{i=1}^{n}{\frac {1}{x_{i}}}\right)^{-1}}
  

For example, the harmonic mean of the five values: 4, 36, 45, 50, 75 is


  
    
      
        
          
            5
            
              
                
                  
                    1
                    4
                  
                
              
              +
              
                
                  
                    1
                    36
                  
                
              
              +
              
                
                  
                    1
                    45
                  
                
              
              +
              
                
                  
                    1
                    50
                  
                
              
              +
              
                
                  
                    1
                    75
                  
                
              
            
          
        
        =
        
          
            5
            
              
              
                
                  
                    1
                    3
                  
                
              
              
            
          
        
        =
        15.
      
    
    {\displaystyle {\frac {5}{{\tfrac {1}{4}}+{\tfrac {1}{36}}+{\tfrac {1}{45}}+{\tfrac {1}{50}}+{\tfrac {1}{75}}}}={\frac {5}{\;{\tfrac {1}{3}}\;}}=15.}
  

Relationship between AM, GM, and HM[edit]
  Proof without words of the inequality of arithmetic and geometric means:PR is a diameter of a circle centred on O; its radius AO is the arithmetic mean of a and b. Using the geometric mean theorem, triangle PGR's altitude GQ is the geometric mean. For any ratio a:b, AO ≥ GQ.
Main article: Inequality of arithmetic and geometric means
AM, GM, and HM satisfy these inequalities:


  
    
      
        
          A
          M
        
        ≥
        
          G
          M
        
        ≥
        
          H
          M
        
        
      
    
    {\displaystyle \mathrm {AM} \geq \mathrm {GM} \geq \mathrm {HM} \,}
  

Equality holds if all the elements of the given sample are equal.

Statistical location[edit]
See also: Average § Statistical location
  it is Comparison of the arithmetic mean, median and mode of two skewed (log-normal) distributions.
  Geometric visualization of the mode, median and mean of an arbitrary probability density function.[3]
In descriptive statistics, the mean may be confused with the median, mode or mid-range, as any of these may be called an "average" (more formally, a measure of central tendency). The mean of a set of observations is the arithmetic average of the values; however, for skewed distributions, the mean is not necessarily the same as the middle value (median), or the most likely value (mode). For example, mean income is typically skewed upwards by a small number of people with very large incomes, so that the majority have an income lower than the mean. By contrast, the median income is the level at which half the population is below and half is above. The mode income is the most likely income and favors the larger number of people with lower incomes. While the median and mode are often more intuitive measures for such skewed data, many skewed distributions are in fact best described by their mean, including the exponential and Poisson distributions.

Mean of a probability distribution[edit]
Main article: Expected value
See also: Population mean
The mean of a probability distribution is the long-run arithmetic average value of a random variable having that distribution. If the random variable is denoted by 
  
    
      
        X
      
    
    {\displaystyle X}
  
, then it is also known as the expected value of 
  
    
      
        X
      
    
    {\displaystyle X}
  
 (denoted 
  
    
      
        E
        (
        X
        )
      
    
    {\displaystyle E(X)}
  
). For a discrete probability distribution, the mean is given by 
  
    
      
        
          ∑
          x
          P
          (
          x
          )
        
      
    
    {\displaystyle \textstyle \sum xP(x)}
  
, where the sum is taken over all possible values of the random variable and 
  
    
      
        P
        (
        x
        )
      
    
    {\displaystyle P(x)}
  
 is the probability mass function. For a continuous distribution, the mean is 
  
    
      
        
          
            ∫
            
              −
              ∞
            
            
              ∞
            
          
          x
          f
          (
          x
          )
          
          d
          x
        
      
    
    {\displaystyle \textstyle \int _{-\infty }^{\infty }xf(x)\,dx}
  
, where 
  
    
      
        f
        (
        x
        )
      
    
    {\displaystyle f(x)}
  
 is the probability density function.[4] In all cases, including those in which the distribution is neither discrete nor continuous, the mean is the Lebesgue integral of the random variable with respect to its probability measure. The mean need not exist or be finite; for some probability distributions the mean is infinite (+∞ or −∞), while for others the mean is undefined.

Generalized means[edit]
Power mean[edit]
The generalized mean, also known as the power mean or Hölder mean, is an abstraction of the quadratic, arithmetic, geometric and harmonic means. It is defined for a set of n positive numbers xi by


  
    
      
        
          
            
              x
              ¯
            
          
        
        (
        m
        )
        =
        
          
            (
            
              
                
                  1
                  n
                
              
              
                ∑
                
                  i
                  =
                  1
                
                
                  n
                
              
              
                x
                
                  i
                
                
                  m
                
              
            
            )
          
          
            
              1
              m
            
          
        
      
    
    {\displaystyle {\bar {x}}(m)=\left({\frac {1}{n}}\sum _{i=1}^{n}x_{i}^{m}\right)^{\frac {1}{m}}}
  
  [2]
By choosing different values for the parameter m, the following types of means are obtained:





  
    
      
        m
        →
        ∞
      
    
    {\displaystyle m\rightarrow \infty }
  

maximum of 
  
    
      
        
          x
          
            i
          
        
      
    
    {\displaystyle x_{i}}
  




  
    
      
        m
        =
        2
      
    
    {\displaystyle m=2}
  

quadratic mean



  
    
      
        m
        =
        1
      
    
    {\displaystyle m=1}
  

arithmetic mean



  
    
      
        m
        →
        0
      
    
    {\displaystyle m\rightarrow 0}
  

geometric mean



  
    
      
        m
        =
        −
        1
      
    
    {\displaystyle m=-1}
  

harmonic mean



  
    
      
        m
        →
        −
        ∞
      
    
    {\displaystyle m\rightarrow -\infty }
  

minimum of 
  
    
      
        
          x
          
            i
          
        
      
    
    {\displaystyle x_{i}}
  


f-mean[edit]
This can be generalized further as the generalized f-mean


  
    
      
        
          
            
              x
              ¯
            
          
        
        =
        
          f
          
            −
            1
          
        
        
          (
          
            
              
                1
                n
              
            
            
              ∑
              
                i
                =
                1
              
              
                n
              
            
            
              f
              
                (
                
                  x
                  
                    i
                  
                
                )
              
            
          
          )
        
      
    
    {\displaystyle {\bar {x}}=f^{-1}\left({{\frac {1}{n}}\sum _{i=1}^{n}{f\left(x_{i}\right)}}\right)}
  

and again a suitable choice of an invertible f will give





  
    
      
        f
        (
        x
        )
        =
        x
      
    
    {\displaystyle f(x)=x}
  

arithmetic mean,



  
    
      
        f
        (
        x
        )
        =
        
          
            1
            x
          
        
      
    
    {\displaystyle f(x)={\frac {1}{x}}}
  

harmonic mean,



  
    
      
        f
        (
        x
        )
        =
        
          x
          
            m
          
        
      
    
    {\displaystyle f(x)=x^{m}}
  

power mean,



  
    
      
        f
        (
        x
        )
        =
        ln
        ⁡
        (
        x
        )
      
    
    {\displaystyle f(x)=\ln(x)}
  

geometric mean.

Weighted arithmetic mean[edit]
The weighted arithmetic mean (or weighted average) is used if one wants to combine average values from different sized samples of the same population:


  
    
      
        
          
            
              x
              ¯
            
          
        
        =
        
          
            
              
                ∑
                
                  i
                  =
                  1
                
                
                  n
                
              
              
                
                  w
                  
                    i
                  
                
                
                  
                    
                      
                        x
                        
                          i
                        
                      
                      ¯
                    
                  
                
              
            
            
              
                ∑
                
                  i
                  =
                  1
                
                
                  n
                
              
              
                w
                
                  i
                
              
            
          
        
        .
      
    
    {\displaystyle {\bar {x}}={\frac {\sum _{i=1}^{n}{w_{i}{\bar {x_{i}}}}}{\sum _{i=1}^{n}w_{i}}}.}
  
  [2]
Where 
  
    
      
        
          
            
              
                x
                
                  i
                
              
              ¯
            
          
        
      
    
    {\displaystyle {\bar {x_{i}}}}
  
 and 
  
    
      
        
          w
          
            i
          
        
      
    
    {\displaystyle w_{i}}
  
 are the mean and size of sample 
  
    
      
        i
      
    
    {\displaystyle i}
  
 respectively. In other applications, they represent a measure for the reliability of the influence upon the mean by the respective values.

Truncated mean[edit]
Sometimes, a set of numbers might contain outliers (i.e., data values which are much lower or much higher than the others). Often, outliers are erroneous data caused by artifacts. In this case, one can use a truncated mean. It involves discarding given parts of the data at the top or the bottom end, typically an equal amount at each end and then taking the arithmetic mean of the remaining data. The number of values removed is indicated as a percentage of the total number of values.

Interquartile mean[edit]
The interquartile mean is a specific example of a truncated mean. It is simply the arithmetic mean after removing the lowest and the highest quarter of values.


  
    
      
        
          
            
              x
              ¯
            
          
        
        =
        
          
            2
            n
          
        
        
        
          ∑
          
            i
            =
            
              
                n
                4
              
            
            +
            1
          
          
            
              
                3
                4
              
            
            n
          
        
        
        
        
          x
          
            i
          
        
      
    
    {\displaystyle {\bar {x}}={\frac {2}{n}}\;\sum _{i={\frac {n}{4}}+1}^{{\frac {3}{4}}n}\!\!x_{i}}
  

assuming the values have been ordered, so is simply a specific example of a weighted mean for a specific set of weights.

Mean of a function[edit]
Main article: Mean of a function
In some circumstances, mathematicians may calculate a mean of an infinite (or even an uncountable) set of values. This can happen when calculating the mean value 
  
    
      
        
          y
          
            avg
          
        
      
    
    {\displaystyle y_{\text{avg}}}
  
 of a function 
  
    
      
        f
        (
        x
        )
      
    
    {\displaystyle f(x)}
  
. Intuitively, a mean of a function can be thought of as calculating the area under a section of a curve, and then dividing by the length of that section. This can be done crudely by counting squares on graph paper, or more precisely by integration. The integration formula is written as:


  
    
      
        
          y
          
            avg
          
        
        (
        a
        ,
        b
        )
        =
        
          
            1
            
              b
              −
              a
            
          
        
        
          ∫
          
            a
          
          
            b
          
        
        
        f
        (
        x
        )
        
        d
        x
      
    
    {\displaystyle y_{\text{avg}}(a,b)={\frac {1}{b-a}}\int \limits _{a}^{b}\!f(x)\,dx}
  

In this case, care must be taken to make sure that the integral converges. But the mean may be finite even if the function itself tends to infinity at some points.

Mean of angles and cyclical quantities[edit]
Angles, times of day, and other cyclical quantities require modular arithmetic to add and otherwise combine numbers. In all these situations, there will not be a unique mean. For example, the times an hour before and after midnight are equidistant to both midnight and noon. It is also possible that no mean exists. Consider a color wheel—there is no mean to the set of all colors. In these situations, you must decide which mean is most useful. You can do this by adjusting the values before averaging, or by using a specialized approach for the mean of circular quantities.

Fréchet mean[edit]
The Fréchet mean gives a manner for determining the "center" of a mass distribution on a surface or, more generally, Riemannian manifold. Unlike many other means, the Fréchet mean is defined on a space whose elements cannot necessarily be added together or multiplied by scalars.
It is sometimes also known as the Karcher mean (named after Hermann Karcher).

Swanson's rule[edit]
This is an approximation to the mean for a moderately skewed distribution.[5] It is used in hydrocarbon exploration and is defined as


  
    
      
        m
        =
        0.3
        
          P
          
            10
          
        
        +
        0.4
        
          P
          
            50
          
        
        +
        0.3
        
          P
          
            90
          
        
      
    
    {\displaystyle m=0.3P_{10}+0.4P_{50}+0.3P_{90}}
  

where P10, P50 and P90 10th, 50th and 90th percentiles of the distribution.

Other means[edit]
Main category: Means
.mw-parser-output .div-col{margin-top:0.3em;column-width:30em}.mw-parser-output .div-col-small{font-size:90%}.mw-parser-output .div-col-rules{column-rule:1px solid #aaa}.mw-parser-output .div-col dl,.mw-parser-output .div-col ol,.mw-parser-output .div-col ul{margin-top:0}.mw-parser-output .div-col li,.mw-parser-output .div-col dd{page-break-inside:avoid;break-inside:avoid-column}
Arithmetic-geometric mean
Arithmetic-harmonic mean
Cesàro mean
Chisini mean
Contraharmonic mean
Elementary symmetric mean
Geometric-harmonic mean
Grand mean
Heinz mean
Heronian mean
Identric mean
Lehmer mean
Logarithmic mean
Moving average
Neuman–Sándor mean
Quasi-arithmetic mean
Root mean square (quadratic mean)
Rényi's entropy (a generalized f-mean)
Spherical mean
Stolarsky mean
Weighted geometric mean
Weighted harmonic mean

See also[edit]
.mw-parser-output .portalbox{float:right;border:solid #aaa 1px;padding:0}.mw-parser-output .portalbox.tleft{margin:0.5em 1em 0.5em 0}.mw-parser-output .portalbox.tright{margin:0.5em 0 0.5em 1em}.mw-parser-output .portalbox>ul{display:table;box-sizing:border-box;padding:0.1em;max-width:175px;background:#f9f9f9;font-size:85%;line-height:110%;font-style:italic;font-weight:bold}.mw-parser-output .portalbox>ul>li{display:table-row}.mw-parser-output .portalbox>ul>li>span:first-child{display:table-cell;padding:0.2em;vertical-align:middle;text-align:center}.mw-parser-output .portalbox>ul>li>span:last-child{display:table-cell;padding:0.2em 0.2em 0.2em 0.3em;vertical-align:middle}

Mathematics portal
Central tendency
Median
Mode
Descriptive statistics
Kurtosis
Law of averages
Mean value theorem
Moment (mathematics)
Summary statistics
Taylor's law
Notes[edit]
.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}

^ Pronounced "x bar".

^ Greek letter μ, for "mean", pronounced /'mjuː/.


References[edit]


^ Underhill, L.G.; Bradfield d. (1998) Introstat, Juta and Company Ltd. .mw-parser-output cite.citation{font-style:inherit}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration{color:#555}.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration span{border-bottom:1px dotted;cursor:help}.mw-parser-output .cs1-ws-icon a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output code.cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;font-size:100%}.mw-parser-output .cs1-visible-error{font-size:100%}.mw-parser-output .cs1-maint{display:none;color:#33aa33;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}ISBN 0-7021-3838-X p. 181

^ a b c "Mean | mathematics". Encyclopedia Britannica. Retrieved 2020-08-21.

^ "AP Statistics Review - Density Curves and the Normal Distributions". Archived from the original on 2 April 2015. Retrieved 16 March 2015.

^ Weisstein, Eric W. "Population Mean". mathworld.wolfram.com. Retrieved 2020-08-21.

^ Hurst A, Brown GC, Swanson  RI (2000) Swanson's 30-40-30 Rule.  American Association of Petroleum Geologists Bulletin 84(12) 1883-1891


.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox th,.mw-parser-output .navbox-title{}.mw-parser-output .navbox-abovebelow,.mw-parser-output th.navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff}.mw-parser-output .navbox-even{background-color:#f7f7f7}.mw-parser-output .navbox-odd{background-color:transparent}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:"[ "}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:" ]"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}.mw-parser-output .infobox .navbar{font-size:100%}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}vteStatistics
Outline
Index
Descriptive statisticsContinuous dataCenter
Mean
arithmetic
geometric
harmonic
cubic
generalized/power
Median
Mode
Dispersion
Variance
Standard deviation
Average absolute deviation
Coefficient of variation
Percentile
Range
Interquartile range
Shape
Central limit theorem
Moments
Skewness
Kurtosis
L-moments
Count data
Index of dispersion
Summary tables
Grouped data
Frequency distribution
Contingency table
Dependence
Pearson product-moment correlation
Rank correlation
Spearman's ρ
Kendall's τ
Partial correlation
Scatter plot
Graphics
Bar chart
Biplot
Box plot
Control chart
Correlogram
Fan chart
Forest plot
Histogram
Pie chart
Q–Q plot
Run chart
Scatter plot
Stem-and-leaf display
Radar chart
Violin plot
Data collectionStudy design
Population
Statistic
Effect size
Statistical power
Optimal design
Sample size determination
Replication
Missing data
Survey methodology
Sampling
stratified
cluster
Standard error
Opinion poll
Questionnaire
Controlled experiments
Scientific control
Randomized experiment
Randomized controlled trial
Random assignment
Blocking
Interaction
Factorial experiment
Adaptive Designs
Adaptive clinical trial
Up-and-Down Designs
Stochastic approximation
Observational Studies
Cross-sectional study
Cohort study
Natural experiment
Quasi-experiment
Statistical inferenceStatistical theory
Population
Statistic
Probability distribution
Sampling distribution
Order statistic
Empirical distribution
Density estimation
Statistical model
Model specification
Lp space
Parameter
location
scale
shape
Parametric family
Likelihood (monotone)
Location–scale family
Exponential family
Completeness
Sufficiency
Statistical functional
Bootstrap
U
V
Optimal decision
loss function
Efficiency
Statistical distance
divergence
Asymptotics
Robustness
Frequentist inferencePoint estimation
Estimating equations
Maximum likelihood
Method of moments
M-estimator
Minimum distance
Unbiased estimators
Mean-unbiased minimum-variance
Rao–Blackwellization
Lehmann–Scheffé theorem
Median unbiased
Plug-in
Interval estimation
Confidence interval
Pivot
Likelihood interval
Prediction interval
Tolerance interval
Resampling
Bootstrap
Jackknife
Testing hypotheses
1- & 2-tails
Power
Uniformly most powerful test
Permutation test
Randomization test
Multiple comparisons
Parametric tests
Likelihood-ratio
Score/Lagrange multiplier
Wald
Specific tests
Z-test (normal)
Student's t-test
F-test
Goodness of fit
Chi-squared
G-test
Kolmogorov–Smirnov
Anderson–Darling
Lilliefors
Jarque–Bera
Normality (Shapiro–Wilk)
Likelihood-ratio test
Model selection
Cross validation
AIC
BIC
Rank statistics
Sign
Sample median
Signed rank (Wilcoxon)
Hodges–Lehmann estimator
Rank sum (Mann–Whitney)
Nonparametric anova
1-way (Kruskal–Wallis)
2-way (Friedman)
Ordered alternative (Jonckheere–Terpstra)
Bayesian inference
Bayesian probability
prior
posterior
Credible interval
Bayes factor
Bayesian estimator
Maximum posterior estimator
CorrelationRegression analysisCorrelation
Pearson product-moment
Partial correlation
Confounding variable
Coefficient of determination
Regression analysis
Errors and residuals
Regression validation
Mixed effects models
Simultaneous equations models
Multivariate adaptive regression splines (MARS)
Linear regression
Simple linear regression
Ordinary least squares
General linear model
Bayesian regression
Non-standard predictors
Nonlinear regression
Nonparametric
Semiparametric
Isotonic
Robust
Heteroscedasticity
Homoscedasticity
Generalized linear model
Exponential families
Logistic (Bernoulli) / Binomial / Poisson regressions
Partition of variance
Analysis of variance (ANOVA, anova)
Analysis of covariance
Multivariate ANOVA
Degrees of freedom
Categorical / Multivariate / Time-series / Survival analysisCategorical
Cohen's kappa
Contingency table
Graphical model
Log-linear model
McNemar's test
Cochran-Mantel-Haenszel statistics
Multivariate
Regression
Manova
Principal components
Canonical correlation
Discriminant analysis
Cluster analysis
Classification
Structural equation model
Factor analysis
Multivariate distributions
Elliptical distributions
Normal
Time-seriesGeneral
Decomposition
Trend
Stationarity
Seasonal adjustment
Exponential smoothing
Cointegration
Structural break
Granger causality
Specific tests
Dickey–Fuller
Johansen
Q-statistic (Ljung–Box)
Durbin–Watson
Breusch–Godfrey
Time domain
Autocorrelation (ACF)
partial (PACF)
Cross-correlation (XCF)
ARMA model
ARIMA model (Box–Jenkins)
Autoregressive conditional heteroskedasticity (ARCH)
Vector autoregression (VAR)
Frequency domain
Spectral density estimation
Fourier analysis
Wavelet
Whittle likelihood
SurvivalSurvival function
Kaplan–Meier estimator (product limit)
Proportional hazards models
Accelerated failure time (AFT) model
First hitting time
Hazard function
Nelson–Aalen estimator
Test
Log-rank test
ApplicationsBiostatistics
Bioinformatics
Clinical trials / studies
Epidemiology
Medical statistics
Engineering statistics
Chemometrics
Methods engineering
Probabilistic design
Process / quality control
Reliability
System identification
Social statistics
Actuarial science
Census
Crime statistics
Demography
Econometrics
Jurimetrics
National accounts
Official statistics
Population statistics
Psychometrics
Spatial statistics
Cartography
Environmental statistics
Geographic information system
Geostatistics
Kriging

Category
 Mathematics portal
Commons
 WikiProject

Authority control General
Integrated Authority File (Germany)
National libraries
United States






Retrieved from "https://en.wikipedia.org/w/index.php?title=Mean&oldid=1052380771"
		Categories: MeansMoment (mathematics)Hidden categories: Articles with short descriptionShort description matches WikidataWikipedia introduction cleanup from October 2021All pages needing cleanupArticles covered by WikiProject Wikify from October 2021All articles covered by WikiProject WikifyArticles with GND identifiersArticles with LCCN identifiers
	